{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1m/71syl3xd3910y8gqrq29f4w40000gn/T/ipykernel_2487/4080736814.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset's\n",
    "\n",
    "#PRODUCTION\n",
    "file_path_production = 'apro_mt_pheadm_page_linear(Slaughterings).csv'\n",
    "df_production = pd.read_csv(file_path_production)\n",
    "\n",
    "#IMPORT PRICE\n",
    "file_path_Import_Price = 'prc_fsc_idx_page_linear (Import price index).csv'\n",
    "df_import_price = pd.read_csv(file_path_Import_Price)\n",
    "\n",
    "#CONSUMER PRICE\n",
    "file_path_Consumer_Price = 'prc_fsc_idx_page_linear (Harmonised index of consumer prices).csv'\n",
    "df_consumer_price = pd.read_csv(file_path_Consumer_Price)\n",
    "\n",
    "#COMMODITY PRICE\n",
    "file_path_Commodity_Price = 'prc_fsc_idx_page_linear (Agricultural commodity price index).csv'\n",
    "df_commodity_price = pd.read_csv(file_path_Commodity_Price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATAFLOW</th>\n",
       "      <th>LAST UPDATE</th>\n",
       "      <th>freq</th>\n",
       "      <th>meat</th>\n",
       "      <th>meatitem</th>\n",
       "      <th>unit</th>\n",
       "      <th>geo</th>\n",
       "      <th>TIME_PERIOD</th>\n",
       "      <th>OBS_VALUE</th>\n",
       "      <th>OBS_FLAG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ESTAT:APRO_MT_PHEADM(1.0)</td>\n",
       "      <td>27/05/24 23:00:00</td>\n",
       "      <td>M</td>\n",
       "      <td>B1000</td>\n",
       "      <td>SL</td>\n",
       "      <td>THS_T</td>\n",
       "      <td>AT</td>\n",
       "      <td>2017-01</td>\n",
       "      <td>18.25</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ESTAT:APRO_MT_PHEADM(1.0)</td>\n",
       "      <td>27/05/24 23:00:00</td>\n",
       "      <td>M</td>\n",
       "      <td>B1000</td>\n",
       "      <td>SL</td>\n",
       "      <td>THS_T</td>\n",
       "      <td>AT</td>\n",
       "      <td>2017-02</td>\n",
       "      <td>17.23</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ESTAT:APRO_MT_PHEADM(1.0)</td>\n",
       "      <td>27/05/24 23:00:00</td>\n",
       "      <td>M</td>\n",
       "      <td>B1000</td>\n",
       "      <td>SL</td>\n",
       "      <td>THS_T</td>\n",
       "      <td>AT</td>\n",
       "      <td>2017-03</td>\n",
       "      <td>20.07</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ESTAT:APRO_MT_PHEADM(1.0)</td>\n",
       "      <td>27/05/24 23:00:00</td>\n",
       "      <td>M</td>\n",
       "      <td>B1000</td>\n",
       "      <td>SL</td>\n",
       "      <td>THS_T</td>\n",
       "      <td>AT</td>\n",
       "      <td>2017-04</td>\n",
       "      <td>17.40</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ESTAT:APRO_MT_PHEADM(1.0)</td>\n",
       "      <td>27/05/24 23:00:00</td>\n",
       "      <td>M</td>\n",
       "      <td>B1000</td>\n",
       "      <td>SL</td>\n",
       "      <td>THS_T</td>\n",
       "      <td>AT</td>\n",
       "      <td>2017-05</td>\n",
       "      <td>19.02</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    DATAFLOW        LAST UPDATE freq   meat meatitem   unit  \\\n",
       "0  ESTAT:APRO_MT_PHEADM(1.0)  27/05/24 23:00:00    M  B1000       SL  THS_T   \n",
       "1  ESTAT:APRO_MT_PHEADM(1.0)  27/05/24 23:00:00    M  B1000       SL  THS_T   \n",
       "2  ESTAT:APRO_MT_PHEADM(1.0)  27/05/24 23:00:00    M  B1000       SL  THS_T   \n",
       "3  ESTAT:APRO_MT_PHEADM(1.0)  27/05/24 23:00:00    M  B1000       SL  THS_T   \n",
       "4  ESTAT:APRO_MT_PHEADM(1.0)  27/05/24 23:00:00    M  B1000       SL  THS_T   \n",
       "\n",
       "  geo TIME_PERIOD  OBS_VALUE OBS_FLAG  \n",
       "0  AT     2017-01      18.25      NaN  \n",
       "1  AT     2017-02      17.23      NaN  \n",
       "2  AT     2017-03      20.07      NaN  \n",
       "3  AT     2017-04      17.40      NaN  \n",
       "4  AT     2017-05      19.02      NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first few rows of the BEEF PRODUCTION (SLAUGHTERINGS) dataset\n",
    "df_production.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATAFLOW</th>\n",
       "      <th>LAST UPDATE</th>\n",
       "      <th>freq</th>\n",
       "      <th>unit</th>\n",
       "      <th>indx</th>\n",
       "      <th>coicop</th>\n",
       "      <th>geo</th>\n",
       "      <th>TIME_PERIOD</th>\n",
       "      <th>OBS_VALUE</th>\n",
       "      <th>OBS_FLAG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ESTAT:PRC_FSC_IDX(1.0)</td>\n",
       "      <td>28/05/24 11:00:00</td>\n",
       "      <td>M</td>\n",
       "      <td>I15</td>\n",
       "      <td>IPI</td>\n",
       "      <td>CP01121</td>\n",
       "      <td>AT</td>\n",
       "      <td>2017-01</td>\n",
       "      <td>99.7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ESTAT:PRC_FSC_IDX(1.0)</td>\n",
       "      <td>28/05/24 11:00:00</td>\n",
       "      <td>M</td>\n",
       "      <td>I15</td>\n",
       "      <td>IPI</td>\n",
       "      <td>CP01121</td>\n",
       "      <td>AT</td>\n",
       "      <td>2017-02</td>\n",
       "      <td>99.3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ESTAT:PRC_FSC_IDX(1.0)</td>\n",
       "      <td>28/05/24 11:00:00</td>\n",
       "      <td>M</td>\n",
       "      <td>I15</td>\n",
       "      <td>IPI</td>\n",
       "      <td>CP01121</td>\n",
       "      <td>AT</td>\n",
       "      <td>2017-03</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ESTAT:PRC_FSC_IDX(1.0)</td>\n",
       "      <td>28/05/24 11:00:00</td>\n",
       "      <td>M</td>\n",
       "      <td>I15</td>\n",
       "      <td>IPI</td>\n",
       "      <td>CP01121</td>\n",
       "      <td>AT</td>\n",
       "      <td>2017-04</td>\n",
       "      <td>94.2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ESTAT:PRC_FSC_IDX(1.0)</td>\n",
       "      <td>28/05/24 11:00:00</td>\n",
       "      <td>M</td>\n",
       "      <td>I15</td>\n",
       "      <td>IPI</td>\n",
       "      <td>CP01121</td>\n",
       "      <td>AT</td>\n",
       "      <td>2017-05</td>\n",
       "      <td>99.9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 DATAFLOW        LAST UPDATE freq unit indx   coicop geo  \\\n",
       "0  ESTAT:PRC_FSC_IDX(1.0)  28/05/24 11:00:00    M  I15  IPI  CP01121  AT   \n",
       "1  ESTAT:PRC_FSC_IDX(1.0)  28/05/24 11:00:00    M  I15  IPI  CP01121  AT   \n",
       "2  ESTAT:PRC_FSC_IDX(1.0)  28/05/24 11:00:00    M  I15  IPI  CP01121  AT   \n",
       "3  ESTAT:PRC_FSC_IDX(1.0)  28/05/24 11:00:00    M  I15  IPI  CP01121  AT   \n",
       "4  ESTAT:PRC_FSC_IDX(1.0)  28/05/24 11:00:00    M  I15  IPI  CP01121  AT   \n",
       "\n",
       "  TIME_PERIOD  OBS_VALUE  OBS_FLAG  \n",
       "0     2017-01       99.7       NaN  \n",
       "1     2017-02       99.3       NaN  \n",
       "2     2017-03      100.0       NaN  \n",
       "3     2017-04       94.2       NaN  \n",
       "4     2017-05       99.9       NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first few rows of the beef IMPORT PRICE dataset\n",
    "df_import_price.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATAFLOW</th>\n",
       "      <th>LAST UPDATE</th>\n",
       "      <th>freq</th>\n",
       "      <th>unit</th>\n",
       "      <th>indx</th>\n",
       "      <th>coicop</th>\n",
       "      <th>geo</th>\n",
       "      <th>TIME_PERIOD</th>\n",
       "      <th>OBS_VALUE</th>\n",
       "      <th>OBS_FLAG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ESTAT:PRC_FSC_IDX(1.0)</td>\n",
       "      <td>28/05/24 11:00:00</td>\n",
       "      <td>M</td>\n",
       "      <td>I15</td>\n",
       "      <td>HICP</td>\n",
       "      <td>CP01121</td>\n",
       "      <td>AT</td>\n",
       "      <td>2017-01</td>\n",
       "      <td>101.52</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ESTAT:PRC_FSC_IDX(1.0)</td>\n",
       "      <td>28/05/24 11:00:00</td>\n",
       "      <td>M</td>\n",
       "      <td>I15</td>\n",
       "      <td>HICP</td>\n",
       "      <td>CP01121</td>\n",
       "      <td>AT</td>\n",
       "      <td>2017-02</td>\n",
       "      <td>99.75</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ESTAT:PRC_FSC_IDX(1.0)</td>\n",
       "      <td>28/05/24 11:00:00</td>\n",
       "      <td>M</td>\n",
       "      <td>I15</td>\n",
       "      <td>HICP</td>\n",
       "      <td>CP01121</td>\n",
       "      <td>AT</td>\n",
       "      <td>2017-03</td>\n",
       "      <td>101.88</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ESTAT:PRC_FSC_IDX(1.0)</td>\n",
       "      <td>28/05/24 11:00:00</td>\n",
       "      <td>M</td>\n",
       "      <td>I15</td>\n",
       "      <td>HICP</td>\n",
       "      <td>CP01121</td>\n",
       "      <td>AT</td>\n",
       "      <td>2017-04</td>\n",
       "      <td>100.32</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ESTAT:PRC_FSC_IDX(1.0)</td>\n",
       "      <td>28/05/24 11:00:00</td>\n",
       "      <td>M</td>\n",
       "      <td>I15</td>\n",
       "      <td>HICP</td>\n",
       "      <td>CP01121</td>\n",
       "      <td>AT</td>\n",
       "      <td>2017-05</td>\n",
       "      <td>103.19</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 DATAFLOW        LAST UPDATE freq unit  indx   coicop geo  \\\n",
       "0  ESTAT:PRC_FSC_IDX(1.0)  28/05/24 11:00:00    M  I15  HICP  CP01121  AT   \n",
       "1  ESTAT:PRC_FSC_IDX(1.0)  28/05/24 11:00:00    M  I15  HICP  CP01121  AT   \n",
       "2  ESTAT:PRC_FSC_IDX(1.0)  28/05/24 11:00:00    M  I15  HICP  CP01121  AT   \n",
       "3  ESTAT:PRC_FSC_IDX(1.0)  28/05/24 11:00:00    M  I15  HICP  CP01121  AT   \n",
       "4  ESTAT:PRC_FSC_IDX(1.0)  28/05/24 11:00:00    M  I15  HICP  CP01121  AT   \n",
       "\n",
       "  TIME_PERIOD  OBS_VALUE OBS_FLAG  \n",
       "0     2017-01     101.52      NaN  \n",
       "1     2017-02      99.75      NaN  \n",
       "2     2017-03     101.88      NaN  \n",
       "3     2017-04     100.32      NaN  \n",
       "4     2017-05     103.19      NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first few rows of the beef CONSUMER PRICE dataset\n",
    "df_consumer_price.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATAFLOW</th>\n",
       "      <th>LAST UPDATE</th>\n",
       "      <th>freq</th>\n",
       "      <th>unit</th>\n",
       "      <th>indx</th>\n",
       "      <th>coicop</th>\n",
       "      <th>geo</th>\n",
       "      <th>TIME_PERIOD</th>\n",
       "      <th>OBS_VALUE</th>\n",
       "      <th>OBS_FLAG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ESTAT:PRC_FSC_IDX(1.0)</td>\n",
       "      <td>25/05/24 11:00:00</td>\n",
       "      <td>M</td>\n",
       "      <td>I15</td>\n",
       "      <td>ACPI</td>\n",
       "      <td>CP01121</td>\n",
       "      <td>AT</td>\n",
       "      <td>2017-01</td>\n",
       "      <td>101.6</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ESTAT:PRC_FSC_IDX(1.0)</td>\n",
       "      <td>25/05/24 11:00:00</td>\n",
       "      <td>M</td>\n",
       "      <td>I15</td>\n",
       "      <td>ACPI</td>\n",
       "      <td>CP01121</td>\n",
       "      <td>AT</td>\n",
       "      <td>2017-02</td>\n",
       "      <td>101.7</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ESTAT:PRC_FSC_IDX(1.0)</td>\n",
       "      <td>25/05/24 11:00:00</td>\n",
       "      <td>M</td>\n",
       "      <td>I15</td>\n",
       "      <td>ACPI</td>\n",
       "      <td>CP01121</td>\n",
       "      <td>AT</td>\n",
       "      <td>2017-03</td>\n",
       "      <td>101.2</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ESTAT:PRC_FSC_IDX(1.0)</td>\n",
       "      <td>25/05/24 11:00:00</td>\n",
       "      <td>M</td>\n",
       "      <td>I15</td>\n",
       "      <td>ACPI</td>\n",
       "      <td>CP01121</td>\n",
       "      <td>AT</td>\n",
       "      <td>2017-04</td>\n",
       "      <td>100.2</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ESTAT:PRC_FSC_IDX(1.0)</td>\n",
       "      <td>25/05/24 11:00:00</td>\n",
       "      <td>M</td>\n",
       "      <td>I15</td>\n",
       "      <td>ACPI</td>\n",
       "      <td>CP01121</td>\n",
       "      <td>AT</td>\n",
       "      <td>2017-05</td>\n",
       "      <td>100.0</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 DATAFLOW        LAST UPDATE freq unit  indx   coicop geo  \\\n",
       "0  ESTAT:PRC_FSC_IDX(1.0)  25/05/24 11:00:00    M  I15  ACPI  CP01121  AT   \n",
       "1  ESTAT:PRC_FSC_IDX(1.0)  25/05/24 11:00:00    M  I15  ACPI  CP01121  AT   \n",
       "2  ESTAT:PRC_FSC_IDX(1.0)  25/05/24 11:00:00    M  I15  ACPI  CP01121  AT   \n",
       "3  ESTAT:PRC_FSC_IDX(1.0)  25/05/24 11:00:00    M  I15  ACPI  CP01121  AT   \n",
       "4  ESTAT:PRC_FSC_IDX(1.0)  25/05/24 11:00:00    M  I15  ACPI  CP01121  AT   \n",
       "\n",
       "  TIME_PERIOD  OBS_VALUE OBS_FLAG  \n",
       "0     2017-01      101.6        e  \n",
       "1     2017-02      101.7        e  \n",
       "2     2017-03      101.2        e  \n",
       "3     2017-04      100.2        e  \n",
       "4     2017-05      100.0        e  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first few rows of the beef COMMODITY PRICE dataset\n",
    "df_commodity_price.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1872 entries, 0 to 1871\n",
      "Data columns (total 10 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   DATAFLOW     1872 non-null   object \n",
      " 1   LAST UPDATE  1872 non-null   object \n",
      " 2   freq         1872 non-null   object \n",
      " 3   meat         1872 non-null   object \n",
      " 4   meatitem     1872 non-null   object \n",
      " 5   unit         1872 non-null   object \n",
      " 6   geo          1872 non-null   object \n",
      " 7   TIME_PERIOD  1872 non-null   object \n",
      " 8   OBS_VALUE    1872 non-null   float64\n",
      " 9   OBS_FLAG     181 non-null    object \n",
      "dtypes: float64(1), object(9)\n",
      "memory usage: 146.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df_production.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1872 entries, 0 to 1871\n",
      "Data columns (total 10 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   DATAFLOW     1872 non-null   object \n",
      " 1   LAST UPDATE  1872 non-null   object \n",
      " 2   freq         1872 non-null   object \n",
      " 3   unit         1872 non-null   object \n",
      " 4   indx         1872 non-null   object \n",
      " 5   coicop       1872 non-null   object \n",
      " 6   geo          1872 non-null   object \n",
      " 7   TIME_PERIOD  1872 non-null   object \n",
      " 8   OBS_VALUE    1872 non-null   float64\n",
      " 9   OBS_FLAG     0 non-null      float64\n",
      "dtypes: float64(2), object(8)\n",
      "memory usage: 146.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df_import_price.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1872 entries, 0 to 1871\n",
      "Data columns (total 10 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   DATAFLOW     1872 non-null   object \n",
      " 1   LAST UPDATE  1872 non-null   object \n",
      " 2   freq         1872 non-null   object \n",
      " 3   unit         1872 non-null   object \n",
      " 4   indx         1872 non-null   object \n",
      " 5   coicop       1872 non-null   object \n",
      " 6   geo          1872 non-null   object \n",
      " 7   TIME_PERIOD  1872 non-null   object \n",
      " 8   OBS_VALUE    1872 non-null   float64\n",
      " 9   OBS_FLAG     6 non-null      object \n",
      "dtypes: float64(1), object(9)\n",
      "memory usage: 146.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df_consumer_price.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1872 entries, 0 to 1871\n",
      "Data columns (total 10 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   DATAFLOW     1872 non-null   object \n",
      " 1   LAST UPDATE  1872 non-null   object \n",
      " 2   freq         1872 non-null   object \n",
      " 3   unit         1872 non-null   object \n",
      " 4   indx         1872 non-null   object \n",
      " 5   coicop       1872 non-null   object \n",
      " 6   geo          1872 non-null   object \n",
      " 7   TIME_PERIOD  1872 non-null   object \n",
      " 8   OBS_VALUE    1872 non-null   float64\n",
      " 9   OBS_FLAG     1872 non-null   object \n",
      "dtypes: float64(1), object(9)\n",
      "memory usage: 146.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df_commodity_price.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison complete.\n"
     ]
    }
   ],
   "source": [
    "# Ensure that all dataframes have the same length\n",
    "if not (len(df_production) == len(df_commodity_price) == len(df_consumer_price) == len(df_import_price)):\n",
    "    print(\"DataFrames do not have the same number of rows.\")\n",
    "else:\n",
    "    # Compare index by index\n",
    "    for index in range(len(df_production)):\n",
    "        time_periods = [df_production.loc[index, 'TIME_PERIOD'], \n",
    "                        df_commodity_price.loc[index, 'TIME_PERIOD'], \n",
    "                        df_consumer_price.loc[index, 'TIME_PERIOD'], \n",
    "                        df_import_price.loc[index, 'TIME_PERIOD']]\n",
    "        \n",
    "        geos = [df_production.loc[index, 'geo'], \n",
    "                df_commodity_price.loc[index, 'geo'], \n",
    "                df_consumer_price.loc[index, 'geo'], \n",
    "                df_import_price.loc[index, 'geo']]\n",
    "        \n",
    "        if not (time_periods[0] == time_periods[1] == time_periods[2] == time_periods[3]):\n",
    "            print(f\"Mismatch in 'TIME_PERIOD' at index {index}: {time_periods}\")\n",
    "        \n",
    "        if not (geos[0] == geos[1] == geos[2] == geos[3]):\n",
    "            print(f\"Mismatch in 'geo' at index {index}: {geos}\")\n",
    "\n",
    "    print(\"Comparison complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATING A NEW DATA FRAME, FIRST CLEANING PRODUCTION DATASET THEN MERGING OBS_VALUE FROM THE PRICE'S DATASET'S\n",
    "\n",
    "# List of columns to remove\n",
    "columns_to_remove = ['DATAFLOW', 'LAST UPDATE', 'freq', 'meat', 'meatitem', 'unit', 'OBS_FLAG']\n",
    "\n",
    "# Remove the specified columns\n",
    "df = df_production.drop(columns=columns_to_remove)\n",
    "\n",
    "#Renaming OBS_VALUE to prod\n",
    "df.rename(columns={'OBS_VALUE': 'prod'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geo</th>\n",
       "      <th>TIME_PERIOD</th>\n",
       "      <th>prod</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AT</td>\n",
       "      <td>2017-01</td>\n",
       "      <td>18.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AT</td>\n",
       "      <td>2017-02</td>\n",
       "      <td>17.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AT</td>\n",
       "      <td>2017-03</td>\n",
       "      <td>20.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AT</td>\n",
       "      <td>2017-04</td>\n",
       "      <td>17.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AT</td>\n",
       "      <td>2017-05</td>\n",
       "      <td>19.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867</th>\n",
       "      <td>SK</td>\n",
       "      <td>2022-08</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1868</th>\n",
       "      <td>SK</td>\n",
       "      <td>2022-09</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1869</th>\n",
       "      <td>SK</td>\n",
       "      <td>2022-10</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1870</th>\n",
       "      <td>SK</td>\n",
       "      <td>2022-11</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1871</th>\n",
       "      <td>SK</td>\n",
       "      <td>2022-12</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1872 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     geo TIME_PERIOD   prod\n",
       "0     AT     2017-01  18.25\n",
       "1     AT     2017-02  17.23\n",
       "2     AT     2017-03  20.07\n",
       "3     AT     2017-04  17.40\n",
       "4     AT     2017-05  19.02\n",
       "...   ..         ...    ...\n",
       "1867  SK     2022-08   0.61\n",
       "1868  SK     2022-09   0.76\n",
       "1869  SK     2022-10   0.64\n",
       "1870  SK     2022-11   0.64\n",
       "1871  SK     2022-12   0.56\n",
       "\n",
       "[1872 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geo</th>\n",
       "      <th>TIME_PERIOD</th>\n",
       "      <th>prod</th>\n",
       "      <th>commodity</th>\n",
       "      <th>consumer</th>\n",
       "      <th>import</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AT</td>\n",
       "      <td>2017-01</td>\n",
       "      <td>18.25</td>\n",
       "      <td>101.6</td>\n",
       "      <td>101.52</td>\n",
       "      <td>99.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AT</td>\n",
       "      <td>2017-02</td>\n",
       "      <td>17.23</td>\n",
       "      <td>101.7</td>\n",
       "      <td>99.75</td>\n",
       "      <td>99.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AT</td>\n",
       "      <td>2017-03</td>\n",
       "      <td>20.07</td>\n",
       "      <td>101.2</td>\n",
       "      <td>101.88</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AT</td>\n",
       "      <td>2017-04</td>\n",
       "      <td>17.40</td>\n",
       "      <td>100.2</td>\n",
       "      <td>100.32</td>\n",
       "      <td>94.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AT</td>\n",
       "      <td>2017-05</td>\n",
       "      <td>19.02</td>\n",
       "      <td>100.0</td>\n",
       "      <td>103.19</td>\n",
       "      <td>99.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  geo TIME_PERIOD   prod  commodity  consumer  import\n",
       "0  AT     2017-01  18.25      101.6    101.52    99.7\n",
       "1  AT     2017-02  17.23      101.7     99.75    99.3\n",
       "2  AT     2017-03  20.07      101.2    101.88   100.0\n",
       "3  AT     2017-04  17.40      100.2    100.32    94.2\n",
       "4  AT     2017-05  19.02      100.0    103.19    99.9"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Merging the OBS_VALUE of datasets on new data frame DF\n",
    "\n",
    "# Define a list of tuples containing the dataset and the new column name\n",
    "datasets = [\n",
    "    (df_commodity_price, 'commodity'),\n",
    "    (df_consumer_price, 'consumer'),\n",
    "    (df_import_price, 'import')\n",
    "]\n",
    "\n",
    "# Merge each dataset with the main DataFrame 'df'\n",
    "for dataset, new_column in datasets:\n",
    "    df = df.merge(\n",
    "        dataset[['TIME_PERIOD', 'geo', 'OBS_VALUE']].rename(columns={'OBS_VALUE': new_column}),\n",
    "        on=['TIME_PERIOD', 'geo'],\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "# Display the first few rows of the merged DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geo</th>\n",
       "      <th>TIME_PERIOD</th>\n",
       "      <th>prod</th>\n",
       "      <th>commodity</th>\n",
       "      <th>consumer</th>\n",
       "      <th>import</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Austria</td>\n",
       "      <td>2017-01</td>\n",
       "      <td>18.25</td>\n",
       "      <td>101.6</td>\n",
       "      <td>101.52</td>\n",
       "      <td>99.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Austria</td>\n",
       "      <td>2017-02</td>\n",
       "      <td>17.23</td>\n",
       "      <td>101.7</td>\n",
       "      <td>99.75</td>\n",
       "      <td>99.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Austria</td>\n",
       "      <td>2017-03</td>\n",
       "      <td>20.07</td>\n",
       "      <td>101.2</td>\n",
       "      <td>101.88</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Austria</td>\n",
       "      <td>2017-04</td>\n",
       "      <td>17.40</td>\n",
       "      <td>100.2</td>\n",
       "      <td>100.32</td>\n",
       "      <td>94.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Austria</td>\n",
       "      <td>2017-05</td>\n",
       "      <td>19.02</td>\n",
       "      <td>100.0</td>\n",
       "      <td>103.19</td>\n",
       "      <td>99.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       geo TIME_PERIOD   prod  commodity  consumer  import\n",
       "0  Austria     2017-01  18.25      101.6    101.52    99.7\n",
       "1  Austria     2017-02  17.23      101.7     99.75    99.3\n",
       "2  Austria     2017-03  20.07      101.2    101.88   100.0\n",
       "3  Austria     2017-04  17.40      100.2    100.32    94.2\n",
       "4  Austria     2017-05  19.02      100.0    103.19    99.9"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!pip install pycountry\n",
    "import pycountry\n",
    "\n",
    "# Custom dictionary for country codes to country names\n",
    "custom_country_mapping = {\n",
    "    'EL': 'Greece',\n",
    "    # Add other custom mappings as needed\n",
    "}\n",
    "\n",
    "# Function to convert country code to country name using both pycountry and custom mapping\n",
    "def combined_get_country_name(code):\n",
    "    if code in custom_country_mapping:\n",
    "        return custom_country_mapping[code]\n",
    "    try:\n",
    "        return pycountry.countries.get(alpha_2=code).name\n",
    "    except AttributeError:\n",
    "        return code\n",
    "\n",
    "# Apply the function to the 'geo' column\n",
    "df['geo'] = df['geo'].apply(combined_get_country_name)\n",
    "\n",
    "# Display the first few rows of the updated dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1872 entries, 0 to 1871\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   geo          1872 non-null   object \n",
      " 1   TIME_PERIOD  1872 non-null   object \n",
      " 2   prod         1872 non-null   float64\n",
      " 3   commodity    1872 non-null   float64\n",
      " 4   consumer     1872 non-null   float64\n",
      " 5   import       1872 non-null   float64\n",
      "dtypes: float64(4), object(2)\n",
      "memory usage: 87.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot the DataFrame by 'TIME_PERIOD' and rename the columns as requested\n",
    "pivot_df = df.pivot(index='TIME_PERIOD', columns='geo', values=['prod', 'commodity', 'consumer', 'import'])\n",
    "\n",
    "# Flatten the MultiIndex columns and rename them\n",
    "pivot_df.columns = [f'{geo}_{metric}' for metric, geo in pivot_df.columns]\n",
    "\n",
    "# Sort the columns alphabetically\n",
    "pivot_df = pivot_df.reindex(sorted(pivot_df.columns), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Austria_commodity</th>\n",
       "      <th>Austria_consumer</th>\n",
       "      <th>Austria_import</th>\n",
       "      <th>Austria_prod</th>\n",
       "      <th>Belgium_commodity</th>\n",
       "      <th>Belgium_consumer</th>\n",
       "      <th>Belgium_import</th>\n",
       "      <th>Belgium_prod</th>\n",
       "      <th>Bulgaria_commodity</th>\n",
       "      <th>Bulgaria_consumer</th>\n",
       "      <th>...</th>\n",
       "      <th>Slovenia_import</th>\n",
       "      <th>Slovenia_prod</th>\n",
       "      <th>Spain_commodity</th>\n",
       "      <th>Spain_consumer</th>\n",
       "      <th>Spain_import</th>\n",
       "      <th>Spain_prod</th>\n",
       "      <th>Sweden_commodity</th>\n",
       "      <th>Sweden_consumer</th>\n",
       "      <th>Sweden_import</th>\n",
       "      <th>Sweden_prod</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TIME_PERIOD</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01</th>\n",
       "      <td>101.6</td>\n",
       "      <td>101.52</td>\n",
       "      <td>99.7</td>\n",
       "      <td>18.25</td>\n",
       "      <td>93.6</td>\n",
       "      <td>100.40</td>\n",
       "      <td>97.9</td>\n",
       "      <td>23.27</td>\n",
       "      <td>84.2</td>\n",
       "      <td>98.01</td>\n",
       "      <td>...</td>\n",
       "      <td>106.2</td>\n",
       "      <td>2.69</td>\n",
       "      <td>105.3</td>\n",
       "      <td>100.65</td>\n",
       "      <td>107.7</td>\n",
       "      <td>50.71</td>\n",
       "      <td>113.6</td>\n",
       "      <td>103.73</td>\n",
       "      <td>96.8</td>\n",
       "      <td>10.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-02</th>\n",
       "      <td>101.7</td>\n",
       "      <td>99.75</td>\n",
       "      <td>99.3</td>\n",
       "      <td>17.23</td>\n",
       "      <td>93.8</td>\n",
       "      <td>101.14</td>\n",
       "      <td>96.3</td>\n",
       "      <td>21.21</td>\n",
       "      <td>85.3</td>\n",
       "      <td>98.19</td>\n",
       "      <td>...</td>\n",
       "      <td>95.7</td>\n",
       "      <td>2.69</td>\n",
       "      <td>105.4</td>\n",
       "      <td>100.44</td>\n",
       "      <td>106.3</td>\n",
       "      <td>48.30</td>\n",
       "      <td>114.5</td>\n",
       "      <td>103.69</td>\n",
       "      <td>95.8</td>\n",
       "      <td>10.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03</th>\n",
       "      <td>101.2</td>\n",
       "      <td>101.88</td>\n",
       "      <td>100.0</td>\n",
       "      <td>20.07</td>\n",
       "      <td>93.8</td>\n",
       "      <td>100.58</td>\n",
       "      <td>99.0</td>\n",
       "      <td>25.41</td>\n",
       "      <td>86.8</td>\n",
       "      <td>98.08</td>\n",
       "      <td>...</td>\n",
       "      <td>107.7</td>\n",
       "      <td>3.17</td>\n",
       "      <td>105.3</td>\n",
       "      <td>100.96</td>\n",
       "      <td>110.7</td>\n",
       "      <td>54.16</td>\n",
       "      <td>114.5</td>\n",
       "      <td>105.22</td>\n",
       "      <td>94.3</td>\n",
       "      <td>11.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-04</th>\n",
       "      <td>100.2</td>\n",
       "      <td>100.32</td>\n",
       "      <td>94.2</td>\n",
       "      <td>17.40</td>\n",
       "      <td>93.8</td>\n",
       "      <td>101.22</td>\n",
       "      <td>97.2</td>\n",
       "      <td>21.79</td>\n",
       "      <td>88.7</td>\n",
       "      <td>97.81</td>\n",
       "      <td>...</td>\n",
       "      <td>105.4</td>\n",
       "      <td>2.87</td>\n",
       "      <td>105.1</td>\n",
       "      <td>100.50</td>\n",
       "      <td>111.7</td>\n",
       "      <td>46.55</td>\n",
       "      <td>113.7</td>\n",
       "      <td>106.41</td>\n",
       "      <td>97.4</td>\n",
       "      <td>9.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05</th>\n",
       "      <td>100.0</td>\n",
       "      <td>103.19</td>\n",
       "      <td>99.9</td>\n",
       "      <td>19.02</td>\n",
       "      <td>93.9</td>\n",
       "      <td>101.14</td>\n",
       "      <td>95.4</td>\n",
       "      <td>25.07</td>\n",
       "      <td>88.8</td>\n",
       "      <td>98.89</td>\n",
       "      <td>...</td>\n",
       "      <td>106.3</td>\n",
       "      <td>2.93</td>\n",
       "      <td>105.1</td>\n",
       "      <td>100.61</td>\n",
       "      <td>112.1</td>\n",
       "      <td>59.12</td>\n",
       "      <td>112.8</td>\n",
       "      <td>106.26</td>\n",
       "      <td>101.4</td>\n",
       "      <td>11.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08</th>\n",
       "      <td>130.4</td>\n",
       "      <td>116.59</td>\n",
       "      <td>129.0</td>\n",
       "      <td>17.66</td>\n",
       "      <td>119.7</td>\n",
       "      <td>113.88</td>\n",
       "      <td>125.9</td>\n",
       "      <td>20.09</td>\n",
       "      <td>140.7</td>\n",
       "      <td>136.54</td>\n",
       "      <td>...</td>\n",
       "      <td>158.0</td>\n",
       "      <td>2.73</td>\n",
       "      <td>136.4</td>\n",
       "      <td>121.95</td>\n",
       "      <td>169.8</td>\n",
       "      <td>65.68</td>\n",
       "      <td>140.6</td>\n",
       "      <td>143.99</td>\n",
       "      <td>159.8</td>\n",
       "      <td>12.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09</th>\n",
       "      <td>130.8</td>\n",
       "      <td>116.28</td>\n",
       "      <td>128.7</td>\n",
       "      <td>17.14</td>\n",
       "      <td>120.2</td>\n",
       "      <td>114.40</td>\n",
       "      <td>132.4</td>\n",
       "      <td>20.76</td>\n",
       "      <td>139.8</td>\n",
       "      <td>140.79</td>\n",
       "      <td>...</td>\n",
       "      <td>155.4</td>\n",
       "      <td>3.24</td>\n",
       "      <td>137.9</td>\n",
       "      <td>121.82</td>\n",
       "      <td>163.1</td>\n",
       "      <td>64.41</td>\n",
       "      <td>141.3</td>\n",
       "      <td>142.64</td>\n",
       "      <td>152.1</td>\n",
       "      <td>12.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10</th>\n",
       "      <td>132.1</td>\n",
       "      <td>115.18</td>\n",
       "      <td>133.1</td>\n",
       "      <td>17.92</td>\n",
       "      <td>121.7</td>\n",
       "      <td>113.85</td>\n",
       "      <td>130.9</td>\n",
       "      <td>19.98</td>\n",
       "      <td>142.4</td>\n",
       "      <td>143.63</td>\n",
       "      <td>...</td>\n",
       "      <td>157.9</td>\n",
       "      <td>3.40</td>\n",
       "      <td>140.4</td>\n",
       "      <td>123.40</td>\n",
       "      <td>158.0</td>\n",
       "      <td>59.37</td>\n",
       "      <td>141.5</td>\n",
       "      <td>141.52</td>\n",
       "      <td>159.2</td>\n",
       "      <td>12.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11</th>\n",
       "      <td>132.9</td>\n",
       "      <td>116.18</td>\n",
       "      <td>129.3</td>\n",
       "      <td>20.44</td>\n",
       "      <td>122.9</td>\n",
       "      <td>115.14</td>\n",
       "      <td>128.9</td>\n",
       "      <td>20.13</td>\n",
       "      <td>143.5</td>\n",
       "      <td>147.68</td>\n",
       "      <td>...</td>\n",
       "      <td>166.3</td>\n",
       "      <td>4.00</td>\n",
       "      <td>142.6</td>\n",
       "      <td>124.44</td>\n",
       "      <td>156.1</td>\n",
       "      <td>58.45</td>\n",
       "      <td>142.0</td>\n",
       "      <td>141.85</td>\n",
       "      <td>148.9</td>\n",
       "      <td>13.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12</th>\n",
       "      <td>133.4</td>\n",
       "      <td>118.84</td>\n",
       "      <td>132.1</td>\n",
       "      <td>18.37</td>\n",
       "      <td>123.8</td>\n",
       "      <td>116.22</td>\n",
       "      <td>139.9</td>\n",
       "      <td>21.12</td>\n",
       "      <td>143.1</td>\n",
       "      <td>152.30</td>\n",
       "      <td>...</td>\n",
       "      <td>164.4</td>\n",
       "      <td>3.43</td>\n",
       "      <td>144.3</td>\n",
       "      <td>126.78</td>\n",
       "      <td>151.1</td>\n",
       "      <td>55.13</td>\n",
       "      <td>142.9</td>\n",
       "      <td>140.24</td>\n",
       "      <td>154.3</td>\n",
       "      <td>11.11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Austria_commodity  Austria_consumer  Austria_import  \\\n",
       "TIME_PERIOD                                                        \n",
       "2017-01                  101.6            101.52            99.7   \n",
       "2017-02                  101.7             99.75            99.3   \n",
       "2017-03                  101.2            101.88           100.0   \n",
       "2017-04                  100.2            100.32            94.2   \n",
       "2017-05                  100.0            103.19            99.9   \n",
       "...                        ...               ...             ...   \n",
       "2022-08                  130.4            116.59           129.0   \n",
       "2022-09                  130.8            116.28           128.7   \n",
       "2022-10                  132.1            115.18           133.1   \n",
       "2022-11                  132.9            116.18           129.3   \n",
       "2022-12                  133.4            118.84           132.1   \n",
       "\n",
       "             Austria_prod  Belgium_commodity  Belgium_consumer  \\\n",
       "TIME_PERIOD                                                      \n",
       "2017-01             18.25               93.6            100.40   \n",
       "2017-02             17.23               93.8            101.14   \n",
       "2017-03             20.07               93.8            100.58   \n",
       "2017-04             17.40               93.8            101.22   \n",
       "2017-05             19.02               93.9            101.14   \n",
       "...                   ...                ...               ...   \n",
       "2022-08             17.66              119.7            113.88   \n",
       "2022-09             17.14              120.2            114.40   \n",
       "2022-10             17.92              121.7            113.85   \n",
       "2022-11             20.44              122.9            115.14   \n",
       "2022-12             18.37              123.8            116.22   \n",
       "\n",
       "             Belgium_import  Belgium_prod  Bulgaria_commodity  \\\n",
       "TIME_PERIOD                                                     \n",
       "2017-01                97.9         23.27                84.2   \n",
       "2017-02                96.3         21.21                85.3   \n",
       "2017-03                99.0         25.41                86.8   \n",
       "2017-04                97.2         21.79                88.7   \n",
       "2017-05                95.4         25.07                88.8   \n",
       "...                     ...           ...                 ...   \n",
       "2022-08               125.9         20.09               140.7   \n",
       "2022-09               132.4         20.76               139.8   \n",
       "2022-10               130.9         19.98               142.4   \n",
       "2022-11               128.9         20.13               143.5   \n",
       "2022-12               139.9         21.12               143.1   \n",
       "\n",
       "             Bulgaria_consumer  ...  Slovenia_import  Slovenia_prod  \\\n",
       "TIME_PERIOD                     ...                                   \n",
       "2017-01                  98.01  ...            106.2           2.69   \n",
       "2017-02                  98.19  ...             95.7           2.69   \n",
       "2017-03                  98.08  ...            107.7           3.17   \n",
       "2017-04                  97.81  ...            105.4           2.87   \n",
       "2017-05                  98.89  ...            106.3           2.93   \n",
       "...                        ...  ...              ...            ...   \n",
       "2022-08                 136.54  ...            158.0           2.73   \n",
       "2022-09                 140.79  ...            155.4           3.24   \n",
       "2022-10                 143.63  ...            157.9           3.40   \n",
       "2022-11                 147.68  ...            166.3           4.00   \n",
       "2022-12                 152.30  ...            164.4           3.43   \n",
       "\n",
       "             Spain_commodity  Spain_consumer  Spain_import  Spain_prod  \\\n",
       "TIME_PERIOD                                                              \n",
       "2017-01                105.3          100.65         107.7       50.71   \n",
       "2017-02                105.4          100.44         106.3       48.30   \n",
       "2017-03                105.3          100.96         110.7       54.16   \n",
       "2017-04                105.1          100.50         111.7       46.55   \n",
       "2017-05                105.1          100.61         112.1       59.12   \n",
       "...                      ...             ...           ...         ...   \n",
       "2022-08                136.4          121.95         169.8       65.68   \n",
       "2022-09                137.9          121.82         163.1       64.41   \n",
       "2022-10                140.4          123.40         158.0       59.37   \n",
       "2022-11                142.6          124.44         156.1       58.45   \n",
       "2022-12                144.3          126.78         151.1       55.13   \n",
       "\n",
       "             Sweden_commodity  Sweden_consumer  Sweden_import  Sweden_prod  \n",
       "TIME_PERIOD                                                                 \n",
       "2017-01                 113.6           103.73           96.8        10.34  \n",
       "2017-02                 114.5           103.69           95.8        10.01  \n",
       "2017-03                 114.5           105.22           94.3        11.60  \n",
       "2017-04                 113.7           106.41           97.4         9.32  \n",
       "2017-05                 112.8           106.26          101.4        11.32  \n",
       "...                       ...              ...            ...          ...  \n",
       "2022-08                 140.6           143.99          159.8        12.18  \n",
       "2022-09                 141.3           142.64          152.1        12.54  \n",
       "2022-10                 141.5           141.52          159.2        12.40  \n",
       "2022-11                 142.0           141.85          148.9        13.31  \n",
       "2022-12                 142.9           140.24          154.3        11.11  \n",
       "\n",
       "[72 rows x 104 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pivot_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pivot_df.to_csv('pivotdf.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ESTATISTICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x12e75a490>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import dash\n",
    "from dash import dcc, html, Input, Output, State\n",
    "import dash_table\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from scipy.stats import ttest_ind, f_oneway, chi2_contingency, ranksums, mannwhitneyu\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "\n",
    "# Assume pivot_df is already loaded into memory\n",
    "# Melt the DataFrame for Plotly\n",
    "melted_df = pivot_df.reset_index().melt(id_vars='TIME_PERIOD', var_name='Country_Metric', value_name='Value')\n",
    "melted_df[['Country', 'Metric']] = melted_df['Country_Metric'].str.split('_', expand=True)\n",
    "\n",
    "# Create a Dash app\n",
    "app = dash.Dash(__name__)\n",
    "\n",
    "# Create the layout for the Dash app\n",
    "app.layout = html.Div([\n",
    "    html.H1(\"Interactive Metrics Dashboard\"),\n",
    "    dcc.Dropdown(\n",
    "        id='country-dropdown',\n",
    "        options=[\n",
    "            {'label': 'All', 'value': 'All'},\n",
    "            {'label': 'None', 'value': 'None'}\n",
    "        ] + [{'label': country, 'value': country} for country in melted_df['Country'].unique()],\n",
    "        value=['All'],\n",
    "        multi=True,\n",
    "        placeholder=\"Select countries\"\n",
    "    ),\n",
    "    dcc.Dropdown(\n",
    "        id='metric-dropdown',\n",
    "        options=[\n",
    "            {'label': 'All', 'value': 'All'},\n",
    "            {'label': 'None', 'value': 'None'}\n",
    "        ] + [{'label': metric, 'value': metric} for metric in ['prod', 'commodity', 'consumer', 'import']],\n",
    "        value=['All'],\n",
    "        multi=True,\n",
    "        placeholder=\"Select metrics\"\n",
    "    ),\n",
    "    dcc.Graph(id='timeseries-graph'),\n",
    "    html.H2(\"Summary Metrics\"),\n",
    "    html.Div(id='summary-table', style={'overflowX': 'scroll'}),\n",
    "    html.H2(\"Inferential Statistics\"),\n",
    "    dcc.Dropdown(\n",
    "        id='t-test-country1',\n",
    "        options=[{'label': country, 'value': country} for country in melted_df['Country'].unique()],\n",
    "        placeholder=\"Select first country\"\n",
    "    ),\n",
    "    dcc.Dropdown(\n",
    "        id='t-test-country2',\n",
    "        options=[{'label': country, 'value': country} for country in melted_df['Country'].unique()],\n",
    "        placeholder=\"Select second country\"\n",
    "    ),\n",
    "    html.Button('Perform Tests', id='perform-tests-button', n_clicks=0),\n",
    "    html.Div(id='test-results', style={'display': 'flex', 'justify-content': 'space-between'}),\n",
    "    html.Div([\n",
    "        html.Div([\n",
    "            html.H3(\"Hypothesis Testing\"),\n",
    "            html.Ul([\n",
    "                html.Li(\"Z test\"),\n",
    "                html.Li(\"F test\"),\n",
    "                html.Li(\"T test\"),\n",
    "                html.Li(\"ANOVA Test\"),\n",
    "                html.Li(\"Wilcoxon Signed Rank Test\"),\n",
    "                html.Li(\"Mann-Whitney U Test\")\n",
    "            ])\n",
    "        ], style={'width': '45%'}),\n",
    "        html.Div([\n",
    "            html.H3(\"Regression Analysis\"),\n",
    "            html.Ul([\n",
    "                html.Li(\"Linear Regression\"),\n",
    "                html.Li(\"Nominal Regression\"),\n",
    "                html.Li(\"Logistic Regression\"),\n",
    "                html.Li(\"Ordinal Regression\")\n",
    "            ])\n",
    "        ], style={'width': '45%'})\n",
    "    ], style={'display': 'flex', 'justify-content': 'space-between'})\n",
    "])\n",
    "\n",
    "# Callback to update the graph and summary table\n",
    "@app.callback(\n",
    "    [Output('timeseries-graph', 'figure'),\n",
    "     Output('summary-table', 'children')],\n",
    "    [Input('country-dropdown', 'value'),\n",
    "     Input('metric-dropdown', 'value')]\n",
    ")\n",
    "def update_figure(selected_countries, selected_metrics):\n",
    "    if 'All' in selected_countries:\n",
    "        selected_countries = melted_df['Country'].unique()\n",
    "    elif 'None' in selected_countries:\n",
    "        selected_countries = []\n",
    "\n",
    "    if 'All' in selected_metrics:\n",
    "        selected_metrics = ['prod', 'commodity', 'consumer', 'import']\n",
    "    elif 'None' in selected_metrics:\n",
    "        selected_metrics = []\n",
    "\n",
    "    # Filter data based on selections\n",
    "    filtered_df = melted_df[melted_df['Country'].isin(selected_countries) & melted_df['Metric'].isin(selected_metrics)]\n",
    "\n",
    "    # Create the time series figure\n",
    "    fig = go.Figure()\n",
    "    for country in selected_countries:\n",
    "        for metric in selected_metrics:\n",
    "            country_metric_df = filtered_df[(filtered_df['Country'] == country) & (filtered_df['Metric'] == metric)]\n",
    "            fig.add_trace(go.Scatter(x=country_metric_df['TIME_PERIOD'], y=country_metric_df['Value'], mode='lines', name=f\"{country} {metric}\"))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title_text=\"Interactive Metrics Over Time\",\n",
    "        xaxis_title=\"Time Period\",\n",
    "        yaxis_title=\"Values\",\n",
    "        legend_title=\"Country and Metric\",\n",
    "        template=\"plotly_white\"\n",
    "    )\n",
    "\n",
    "    # Create the summary table for selected countries\n",
    "    selected_cols = [col for col in pivot_df.columns if col.split('_')[0] in selected_countries]\n",
    "    \n",
    "    if selected_cols:\n",
    "        selected_df = pivot_df[selected_cols]\n",
    "        summary = selected_df.describe().reset_index()\n",
    "        summary_table = dash_table.DataTable(\n",
    "            columns=[{\"name\": i, \"id\": i} for i in summary.columns],\n",
    "            data=summary.to_dict('records'),\n",
    "            style_table={'overflowX': 'auto'},\n",
    "            style_cell={'textAlign': 'left'}\n",
    "        )\n",
    "    else:\n",
    "        summary_table = html.Div(\"No data available for the selected countries.\")\n",
    "\n",
    "    return fig, summary_table\n",
    "\n",
    "# Callback to perform the t-test, ANOVA, and Chi-Square tests\n",
    "@app.callback(\n",
    "    Output('test-results', 'children'),\n",
    "    [Input('perform-tests-button', 'n_clicks')],\n",
    "    [State('t-test-country1', 'value'),\n",
    "     State('t-test-country2', 'value'),\n",
    "     State('metric-dropdown', 'value')]\n",
    ")\n",
    "def perform_tests(n_clicks, country1, country2, selected_metrics):\n",
    "    if n_clicks > 0 and country1 and country2:\n",
    "        hypothesis_results = []\n",
    "        regression_results = []\n",
    "        if 'All' in selected_metrics or not selected_metrics:\n",
    "            selected_metrics = ['prod', 'commodity', 'consumer', 'import']\n",
    "        for metric in selected_metrics:\n",
    "            col1 = f\"{country1}_{metric}\"\n",
    "            col2 = f\"{country2}_{metric}\"\n",
    "            if col1 in pivot_df.columns and col2 in pivot_df.columns:\n",
    "                data1 = pivot_df[col1].dropna()\n",
    "                data2 = pivot_df[col2].dropna()\n",
    "                if not data1.empty and not data2.empty:\n",
    "                    # t-test\n",
    "                    t_stat, p_value_t = ttest_ind(data1, data2)\n",
    "                    # ANOVA\n",
    "                    anova_stat, p_value_anova = f_oneway(data1, data2)\n",
    "                    # Chi-Square (binning the continuous data for chi-square test)\n",
    "                    data1_binned = pd.cut(data1, bins=10, labels=False)\n",
    "                    data2_binned = pd.cut(data2, bins=10, labels=False)\n",
    "                    contingency_table = pd.crosstab(data1_binned, data2_binned)\n",
    "                    chi2_stat, p_value_chi2, dof, ex = chi2_contingency(contingency_table)\n",
    "                    # Wilcoxon Signed Rank Test\n",
    "                    wilcoxon_stat, p_value_wilcoxon = ranksums(data1, data2)\n",
    "                    # Mann-Whitney U Test\n",
    "                    mannwhitney_stat, p_value_mannwhitney = mannwhitneyu(data1, data2)\n",
    "\n",
    "                    hypothesis_results.append(html.Div([\n",
    "                        html.H4(f\"Metric: {metric}\"),\n",
    "                        html.P(f\"t-test: t-statistic = {t_stat:.2f}, p-value = {p_value_t:.4f}\"),\n",
    "                        html.P(f\"ANOVA: F-statistic = {anova_stat:.2f}, p-value = {p_value_anova:.4f}\"),\n",
    "                        html.P(f\"Chi-Square: chi2-statistic = {chi2_stat:.2f}, p-value = {p_value_chi2:.4f}\"),\n",
    "                        html.P(f\"Wilcoxon Signed Rank Test: statistic = {wilcoxon_stat:.2f}, p-value = {p_value_wilcoxon:.4f}\"),\n",
    "                        html.P(f\"Mann-Whitney U Test: U-statistic = {mannwhitney_stat:.2f}, p-value = {p_value_mannwhitney:.4f}\")\n",
    "                    ]))\n",
    "\n",
    "                    # Perform Regression Analysis (placeholders)\n",
    "                    if len(data1) == len(data2):\n",
    "                        X = np.array(data1).reshape(-1, 1)\n",
    "                        y = np.array(data2)\n",
    "                        \n",
    "                        # Linear Regression\n",
    "                        model = LinearRegression().fit(X, y)\n",
    "                        lin_reg_score = model.score(X, y)\n",
    "                        \n",
    "                        # Logistic Regression (with binarized target for demonstration)\n",
    "                        y_bin = (y > y.mean()).astype(int)\n",
    "                        log_model = LogisticRegression().fit(X, y_bin)\n",
    "                        log_reg_score = log_model.score(X, y_bin)\n",
    "\n",
    "                        # Nominal Regression (Placeholder)\n",
    "                        nominal_reg_score = \"Not Implemented\"\n",
    "\n",
    "                        # Ordinal Regression (Placeholder)\n",
    "                        ordinal_reg_score = \"Not Implemented\"\n",
    "\n",
    "                        regression_results.append(html.Div([\n",
    "                            html.H4(f\"Regression Analysis: {metric}\"),\n",
    "                            html.P(f\"Linear Regression R^2: {lin_reg_score:.4f}\"),\n",
    "                            html.P(f\"Logistic Regression Accuracy: {log_reg_score:.4f}\"),\n",
    "                            html.P(f\"Nominal Regression: {nominal_reg_score}\"),\n",
    "                            html.P(f\"Ordinal Regression: {ordinal_reg_score}\")\n",
    "                        ]))\n",
    "                \n",
    "        return html.Div([\n",
    "            html.Div(hypothesis_results, style={'width': '45%'}),\n",
    "            html.Div(regression_results, style={'width': '45%'})\n",
    "        ], style={'display': 'flex', 'justify-content': 'space-between'})\n",
    "    return html.Div(\"Select two countries and metrics to perform the tests.\")\n",
    "\n",
    "# Run the app\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Chi-Square Test\n",
    "Chi-square tests are typically used for categorical data, but we can still demonstrate its use with a hypothetical contingency table. Assume we want to see if there's a significant difference in OBS_VALUE counts over specific ranges for Ireland and Italy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pivoted_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m chi2_contingency\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Create a contingency table\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m contingency_table \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mcrosstab(pd\u001b[38;5;241m.\u001b[39mcut(\u001b[43mpivoted_data\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIreland\u001b[39m\u001b[38;5;124m'\u001b[39m], bins\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m), pd\u001b[38;5;241m.\u001b[39mcut(pivoted_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mItaly\u001b[39m\u001b[38;5;124m'\u001b[39m], bins\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m))\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Perform Chi-Square test\u001b[39;00m\n\u001b[1;32m      7\u001b[0m chi2_stat, p_value, dof, ex \u001b[38;5;241m=\u001b[39m chi2_contingency(contingency_table)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pivoted_data' is not defined"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing tests for prod: Belgium vs Cyprus\n",
      "Data for Belgium_prod: count    72.000000\n",
      "mean     21.700417\n",
      "std       1.767809\n",
      "min      16.860000\n",
      "25%      20.570000\n",
      "50%      21.395000\n",
      "75%      23.060000\n",
      "max      25.410000\n",
      "Name: Belgium_prod, dtype: float64\n",
      "Data for Cyprus_prod: count    72.000000\n",
      "mean      0.489722\n",
      "std       0.198182\n",
      "min       0.270000\n",
      "25%       0.400000\n",
      "50%       0.430000\n",
      "75%       0.512500\n",
      "max       1.230000\n",
      "Name: Cyprus_prod, dtype: float64\n",
      "Performing tests for commodity: Belgium vs Cyprus\n",
      "Data for Belgium_commodity: count     72.000000\n",
      "mean     103.454167\n",
      "std        9.412113\n",
      "min       92.900000\n",
      "25%       95.850000\n",
      "50%      100.300000\n",
      "75%      108.075000\n",
      "max      123.800000\n",
      "Name: Belgium_commodity, dtype: float64\n",
      "Data for Cyprus_commodity: count     72.000000\n",
      "mean     104.273611\n",
      "std       10.288569\n",
      "min       85.000000\n",
      "25%       97.100000\n",
      "50%      104.750000\n",
      "75%      110.900000\n",
      "max      125.300000\n",
      "Name: Cyprus_commodity, dtype: float64\n",
      "Performing tests for consumer: Belgium vs Cyprus\n",
      "Data for Belgium_consumer: count     72.000000\n",
      "mean     103.412917\n",
      "std        4.017005\n",
      "min       99.520000\n",
      "25%      100.800000\n",
      "50%      101.815000\n",
      "75%      104.410000\n",
      "max      116.220000\n",
      "Name: Belgium_consumer, dtype: float64\n",
      "Data for Cyprus_consumer: count     72.000000\n",
      "mean     105.520417\n",
      "std        6.990585\n",
      "min      100.160000\n",
      "25%      101.915000\n",
      "50%      103.995000\n",
      "75%      104.717500\n",
      "max      132.960000\n",
      "Name: Cyprus_consumer, dtype: float64\n",
      "Performing tests for import: Belgium vs Cyprus\n",
      "Data for Belgium_import: count     72.000000\n",
      "mean     105.830556\n",
      "std       12.861545\n",
      "min       90.900000\n",
      "25%       97.875000\n",
      "50%      101.250000\n",
      "75%      104.625000\n",
      "max      142.000000\n",
      "Name: Belgium_import, dtype: float64\n",
      "Data for Cyprus_import: count     72.000000\n",
      "mean     117.201389\n",
      "std       19.097507\n",
      "min       96.400000\n",
      "25%      104.675000\n",
      "50%      109.400000\n",
      "75%      121.475000\n",
      "max      171.400000\n",
      "Name: Cyprus_import, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Create a contingency table\n",
    "contingency_table = pd.crosstab(pd.cut(pivoted_data['Ireland'], bins=5), pd.cut(pivoted_data['Italy'], bins=5))\n",
    "\n",
    "# Perform Chi-Square test\n",
    "chi2_stat, p_value, dof, ex = chi2_contingency(contingency_table)\n",
    "\n",
    "print(f\"Chi2 Statistic: {chi2_stat}, P-value: {p_value}, Degrees of freedom: {dof}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Correlation Analysis\n",
    "Let's calculate the Pearson correlation coefficient between OBS_VALUE of Ireland and Italy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Pearson correlation\n",
    "correlation = pivoted_data['Ireland'].corr(pivoted_data['Italy'])\n",
    "\n",
    "print(f\"Pearson Correlation: {correlation}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Regression Analysis\n",
    "Let's perform a simple linear regression analysis where we predict the OBS_VALUE of Ireland based on the OBS_VALUE of Italy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# Define the independent variable (Ireland) and the dependent variable (Italy)\n",
    "X = pivoted_data['Ireland']\n",
    "y = pivoted_data['Italy']\n",
    "\n",
    "# Add a constant to the independent variable\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit the regression model\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Get the regression results summary\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivoted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# Load the pivoted data\n",
    "file_path = 'tag00044_linear_pivoted_final.csv'\n",
    "#pivoted_data = pd.read_csv(file_path, index_col='TIME_PERIOD')\n",
    "\n",
    "# Reset index temporarily to melt the DataFrame\n",
    "pivoted_data_reset = pivoted_data.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an interactive line plot\n",
    "fig_line = px.line(long_data, x='TIME_PERIOD', y='OBS_VALUE', color='Country', markers=True)\n",
    "\n",
    "# Set the plot title and labels for the line plot\n",
    "fig_line.update_layout(\n",
    "    title='Trend of OBS_VALUE Over TIME_PERIOD for Each Country',\n",
    "    xaxis_title='Time Period',\n",
    "    yaxis_title='OBS_VALUE'\n",
    ")\n",
    "\n",
    "# Prepare data for the choropleth map (using the last available year in the dataset)\n",
    "map_data = long_data[long_data['TIME_PERIOD'] == long_data['TIME_PERIOD'].max()]\n",
    "\n",
    "# Create the choropleth map\n",
    "fig_map = px.choropleth(\n",
    "    map_data,\n",
    "    locations='Country', \n",
    "    locationmode='country names',\n",
    "    color='OBS_VALUE',\n",
    "    hover_name='Country',\n",
    "    color_continuous_scale=px.colors.sequential.Plasma,\n",
    "    title='OBS_VALUE by Country for the Most Recent Year'\n",
    ")\n",
    "\n",
    "# Combine both visualizations\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=1,\n",
    "    subplot_titles=(\"OBS_VALUE by Country for the Most Recent Year\", \"Trend of OBS_VALUE Over TIME_PERIOD\"),\n",
    "    specs=[[{\"type\": \"choropleth\"}], [{\"type\": \"xy\"}]],\n",
    "    row_heights=[0.6, 0.4]  # Make the map row larger\n",
    ")\n",
    "\n",
    "# Add choropleth map to the first row\n",
    "for trace in fig_map.data:\n",
    "    fig.add_trace(trace, row=1, col=1)\n",
    "\n",
    "# Add line plot to the second row\n",
    "for trace in fig_line.data:\n",
    "    fig.add_trace(trace, row=2, col=1)\n",
    "\n",
    "# Update layout and map to focus on Europe\n",
    "fig.update_layout(\n",
    "    height=900,\n",
    "    showlegend=False,\n",
    "    geo=dict(\n",
    "        scope='europe',\n",
    "        projection_type='natural earth'\n",
    "    )\n",
    ")\n",
    "\n",
    "# Show the combined plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# Load your data here, ensuring long_data is prepared\n",
    "# long_data = ...\n",
    "\n",
    "# Prepare data for the choropleth map (using the last available year in the dataset)\n",
    "map_data = long_data[long_data['TIME_PERIOD'] == long_data['TIME_PERIOD'].max()]\n",
    "\n",
    "# Create the choropleth map focused on Europe\n",
    "fig_map = px.choropleth(\n",
    "    map_data,\n",
    "    locations='Country', \n",
    "    locationmode='country names',\n",
    "    color='OBS_VALUE',\n",
    "    hover_name='Country',\n",
    "    color_continuous_scale=px.colors.sequential.Plasma,\n",
    "    title='OBS_VALUE by Country for the Most Recent Year'\n",
    ")\n",
    "\n",
    "# Update the map to focus on Western Europe and include the legend\n",
    "fig_map.update_geos(\n",
    "    projection_type='natural earth',\n",
    "    lataxis_range=[35, 70],  # Approximate latitude range for Western Europe\n",
    "    lonaxis_range=[-10, 30]  # Approximate longitude range for Western Europe\n",
    ")\n",
    "\n",
    "# Show the map with the legend\n",
    "fig_map.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
