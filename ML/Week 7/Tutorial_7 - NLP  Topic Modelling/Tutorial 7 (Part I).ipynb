{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc0c299f",
   "metadata": {},
   "source": [
    "# Tutorial 7 (Part I)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284539f2",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "Whether you are referring to Twitter, Goodreads, or Amazon, there is scarcely any digital place that is not overrun with peoples' opinions. In the modern world, it is vital for businesses to delve into these perspectives and gain knowledge about their goods or services. However, the sheer volume of this data makes it virtually hard to measure it manually. Sentiment Analysis, yet another benefit of data science, enters the picture at this point. In this post, we'll examine what sentiment analysis entails and the many Python implementations that are available.\n",
    "\n",
    "## What is Sentiment Analysis?\n",
    "Sentiment analysis falls under the heading of text classification and is a use case of natural language processing (NLP). Simply described, sentiment analysis includes categorizing a text into several emotions, such as happy or sad, neutral, or happy or sad. Determining the underlying tone, emotion, or sentiment of a document is the ultimate goal of sentiment analysis. Another name for this is opinion mining.\n",
    "\n",
    "## VADER\n",
    "VADER (Valence Aware Dictionary and sEntiment Reasoner) is a rule-based sentiment analyzer that has been trained on social media text. Just like Text Blob, its usage in Python is pretty simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a221b95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') # We can suppress the warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd00edae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting vaderSentiment\n",
      "  Obtaining dependency information for vaderSentiment from https://files.pythonhosted.org/packages/76/fc/310e16254683c1ed35eeb97386986d6c00bc29df17ce280aed64d55537e9/vaderSentiment-3.3.2-py2.py3-none-any.whl.metadata\n",
      "  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl.metadata (572 bytes)\n",
      "Requirement already satisfied: requests in c:\\users\\miqba\\anaconda3\\lib\\site-packages (from vaderSentiment) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\miqba\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\miqba\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\miqba\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\miqba\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (2024.2.2)\n",
      "Using cached vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n",
      "Installing collected packages: vaderSentiment\n",
      "Successfully installed vaderSentiment-3.3.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "485b1cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment of text 1: {'neg': 0.0, 'neu': 0.73, 'pos': 0.27, 'compound': 0.5719}\n",
      "Sentiment of text 2: {'neg': 0.508, 'neu': 0.492, 'pos': 0.0, 'compound': -0.4767}\n"
     ]
    }
   ],
   "source": [
    "# Load thelibraries\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# Create and initialise an object\n",
    "sentiment = SentimentIntensityAnalyzer()\n",
    "text_1 = \"The book was a perfect balance between wrtiting style and plot.\"\n",
    "text_2 =  \"The pizza tastes terrible.\"\n",
    "\n",
    "sent_1 = sentiment.polarity_scores(text_1)\n",
    "sent_2 = sentiment.polarity_scores(text_2)\n",
    "\n",
    "print(\"Sentiment of text 1:\", sent_1)\n",
    "print(\"Sentiment of text 2:\", sent_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3cdcbd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\miqba\\anaconda3\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\miqba\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\miqba\\anaconda3\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\miqba\\anaconda3\\lib\\site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in c:\\users\\miqba\\anaconda3\\lib\\site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\miqba\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\miqba\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Install and import nltk\n",
    "!pip install nltk\n",
    "import nltk\n",
    "\n",
    "# Download the lexicon\n",
    "nltk.download(\"vader_lexicon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6989217f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.0, 'neu': 0.585, 'pos': 0.415, 'compound': 0.75}\n"
     ]
    }
   ],
   "source": [
    "# Import the lexicon \n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# Create an instance of SentimentIntensityAnalyzer\n",
    "sent_analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Example\n",
    "sentence = \"VADER is pretty good at identifying the underlying sentiment of a text!\"\n",
    "print(sent_analyzer.polarity_scores(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f08915",
   "metadata": {},
   "source": [
    "* a positive sentiment, compound â‰¥ 0.05.\n",
    "* a negative sentiment, compound â‰¤ -0.05.\n",
    "* a neutral sentiment, the compound is between ]-0.05, 0.05[\n",
    "\n",
    "The previous result shows that the sentence does not have any negative information (neg=0). It has some neutral and positive tones (neu=0.585 and pos=0.415). However, the overall sentiment is positive, because compound > 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "962ce5c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.0, 'neu': 0.373, 'pos': 0.627, 'compound': 0.8284}\n"
     ]
    }
   ],
   "source": [
    "# What about this sentence with repeated exclamations and capitalization?\n",
    "sentence_ = \"VADER is a REALLY AMAZING library!!!!\"\n",
    "print(sent_analyzer.polarity_scores(sentence_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0cd518",
   "metadata": {},
   "source": [
    "As you can see from this example, the compound jumped to 0.82, which makes the sentence more positive than the one before, as per the value of the compound."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a977eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.619, 'neu': 0.381, 'pos': 0.0, 'compound': -0.8449}\n"
     ]
    }
   ],
   "source": [
    "# A last example with negative sentiment\n",
    "negative_sent = \"I do HATE those fake news on internet!!ðŸ˜¡\"\n",
    "print(sent_analyzer.polarity_scores(negative_sent))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59567e2",
   "metadata": {},
   "source": [
    "From this last sentence, we can see that the sentence does not have any positive information (pos = 0). It has some neutral and positive tones (neu = 0.424 and neg = 0.576). However, the overall sentiment is negative, because compound < -0.05. Removing the exclamations will make the sentiment less negative."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81769ee",
   "metadata": {},
   "source": [
    "## VADER on Large Dataset\n",
    "We are going to use this license-free tweets dataset available on the Sentiment140 website, in order to know how well VADER does. Before that, we are going to use this helper function which will immediately return the polarity (pos, neg, or neu) instead of the dictionary output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4aacb2a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>4</th>\n",
       "      <th>3</th>\n",
       "      <th>Mon May 11 03:17:40 UTC 2009</th>\n",
       "      <th>kindle2</th>\n",
       "      <th>tpryan</th>\n",
       "      <th>@stellargirl I loooooooovvvvvveee my Kindle2. Not that the DX is cool, but the 2 is fantastic in its own right.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Mon May 11 03:18:03 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>vcu451</td>\n",
       "      <td>Reading my kindle2...  Love it... Lee childs i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Mon May 11 03:18:54 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>chadfu</td>\n",
       "      <td>Ok, first assesment of the #kindle2 ...it fuck...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>Mon May 11 03:19:04 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>SIX15</td>\n",
       "      <td>@kenburbary You'll love your Kindle2. I've had...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>Mon May 11 03:21:41 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>yamarama</td>\n",
       "      <td>@mikefish  Fair enough. But i have the Kindle2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>Mon May 11 03:22:00 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>GeorgeVHulme</td>\n",
       "      <td>@richardebaker no. it is too big. I'm quite ha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   4  3  Mon May 11 03:17:40 UTC 2009  kindle2        tpryan  \\\n",
       "0  4  4  Mon May 11 03:18:03 UTC 2009  kindle2        vcu451   \n",
       "1  4  5  Mon May 11 03:18:54 UTC 2009  kindle2        chadfu   \n",
       "2  4  6  Mon May 11 03:19:04 UTC 2009  kindle2         SIX15   \n",
       "3  4  7  Mon May 11 03:21:41 UTC 2009  kindle2      yamarama   \n",
       "4  4  8  Mon May 11 03:22:00 UTC 2009  kindle2  GeorgeVHulme   \n",
       "\n",
       "  @stellargirl I loooooooovvvvvveee my Kindle2. Not that the DX is cool, but the 2 is fantastic in its own right.  \n",
       "0  Reading my kindle2...  Love it... Lee childs i...                                                               \n",
       "1  Ok, first assesment of the #kindle2 ...it fuck...                                                               \n",
       "2  @kenburbary You'll love your Kindle2. I've had...                                                               \n",
       "3  @mikefish  Fair enough. But i have the Kindle2...                                                               \n",
       "4  @richardebaker no. it is too big. I'm quite ha...                                                               "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the data set\n",
    "data_url = \"https://raw.githubusercontent.com/keitazoumana/VADER_sentiment-Analysis/main/data/testdata.manual.2009.06.14.csv\"\n",
    "sentiment_data = pd.read_csv(data_url)\n",
    "\n",
    "sentiment_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f65276",
   "metadata": {},
   "source": [
    "We are only interested in two columns.\n",
    "\n",
    "'4' corresponding to the polarity of the tweet (0 = negative, 2 = neutral, 4 = positive).\n",
    "'@stellargi..right' corresponding to the actual tweet.\n",
    "Let format the dataset for better clarification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de092260",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_data(data):\n",
    "\n",
    "    last_col = str(data.columns[-1])\n",
    "    first_col = str(data.columns[0])\n",
    "\n",
    "    data.rename(columns = {last_col: 'tweet_text', first_col: 'polarity'}, inplace=True) \n",
    "\n",
    "    # Change 0, 2, 4 to negative, neutral and positive\n",
    "    labels = {0: 'negative', 2: 'neutral', 4: 'positive'}\n",
    "    data['polarity'] = data['polarity'].map(labels)\n",
    "\n",
    "    # Get only the two columns\n",
    "    return data[['tweet_text', 'polarity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0d56fc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reading my kindle2...  Love it... Lee childs i...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ok, first assesment of the #kindle2 ...it fuck...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@kenburbary You'll love your Kindle2. I've had...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text  polarity\n",
       "0  Reading my kindle2...  Love it... Lee childs i...  positive\n",
       "1  Ok, first assesment of the #kindle2 ...it fuck...  positive\n",
       "2  @kenburbary You'll love your Kindle2. I've had...  positive"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = format_data(sentiment_data)\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aee7ccea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_output(output_dict):\n",
    "  \n",
    "  polarity = \"neutral\"\n",
    "\n",
    "  if(output_dict['compound'] >= 0.05):\n",
    "    polarity = \"positive\"\n",
    "\n",
    "  elif(output_dict['compound'] <= -0.05):\n",
    "    polarity = \"negative\"\n",
    "\n",
    "  return polarity\n",
    "\n",
    "def predict_sentiment(text):\n",
    "  \n",
    "  output_dict =  sent_analyzer.polarity_scores(text)\n",
    "  return format_output(output_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1650eb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"vader_prediction\"] = data[\"tweet_text\"].apply(predict_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93cf810f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>polarity</th>\n",
       "      <th>vader_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>is upset about the whole GM thing. life as i k...</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>How do you use the twitter API?... http://bit....</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>annoying new trend on the internets:  people p...</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>First dentist appointment [in years] on Wednes...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>eating breakfast and then school</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            tweet_text  polarity  \\\n",
       "383  is upset about the whole GM thing. life as i k...  negative   \n",
       "299  How do you use the twitter API?... http://bit....   neutral   \n",
       "53   annoying new trend on the internets:  people p...  negative   \n",
       "411  First dentist appointment [in years] on Wednes...   neutral   \n",
       "427                   eating breakfast and then school   neutral   \n",
       "\n",
       "    vader_prediction  \n",
       "383         negative  \n",
       "299          neutral  \n",
       "53          negative  \n",
       "411          neutral  \n",
       "427          neutral  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46102ed",
   "metadata": {},
   "source": [
    "## VADER Performance on the Dataset.\n",
    "From the original polarity column and VADER's prediction we can generate the confusion matrix and its overall performance (precision, recall, and f1 score)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a308bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.716297786720322\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.64      0.72       177\n",
      "     neutral       0.67      0.70      0.68       139\n",
      "    positive       0.67      0.81      0.73       181\n",
      "\n",
      "    accuracy                           0.72       497\n",
      "   macro avg       0.73      0.71      0.71       497\n",
      "weighted avg       0.73      0.72      0.72       497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "accuracy = accuracy_score(data['polarity'], data['vader_prediction'])\n",
    "\n",
    "print(\"Accuracy: {}\\n\".format(accuracy))\n",
    "\n",
    "# Show the classification report\n",
    "print(classification_report(data['polarity'], data['vader_prediction']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2cd9dd",
   "metadata": {},
   "source": [
    "The model seems to be doing a good job because it is much better than a random guess (accuracy = 0.5)! The same observation can be made from the f1-scores of each polarity. Before diving into building machine learning models, it might be better to take VADER as your baseline model for such a task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db25061",
   "metadata": {},
   "source": [
    "# Bag of Words Vectorization-Based Models\n",
    "In the two approaches, Bag of words and Vader, we have simply used Python libraries to perform sentiment analysis. Now we will discuss an approach wherein we train our own model for the task. The steps involved in performing sentiment analysis using the Bag of Words Vectorization method are as follows\n",
    "\n",
    "Pre-Process the text of training data (Text pre-processing involves Normalization, Tokenization, Stopwords Removal, and Stemming/Lemmatization.)\n",
    "\n",
    "Create a Bag of Words for the pre-processed text data using the <b>Count Vectorization</b> or <b>TF-IDF Vectorization</b> approach.\n",
    "Train a suitable classification model on the processed data for sentiment classification.\n",
    "\n",
    "## Code for Sentiment Analysis using Bag of Words Vectorization Approach:\n",
    "\n",
    "To build a sentiment analysis model using the BOW Vectorization Approach we need a labeled dataset. As stated earlier, the dataset used for this demonstration has been obtained from Kaggle. We have simply used sklearnâ€™s count vectorizer to create the BOW. After, we trained a Multinomial Naive Bayes classifier, for which an accuracy score of 0.84 was obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e4483db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The GeoSolutions technology will leverage Bene...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$ESI on lows, down $1.50 to $2.50 BK a real po...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>For the last quarter of 2010 , Componenta 's n...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>According to the Finnish-Russian Chamber of Co...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Swedish buyout firm has sold its remaining...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence Sentiment\n",
       "0  The GeoSolutions technology will leverage Bene...  positive\n",
       "1  $ESI on lows, down $1.50 to $2.50 BK a real po...  negative\n",
       "2  For the last quarter of 2010 , Componenta 's n...  positive\n",
       "3  According to the Finnish-Russian Chamber of Co...   neutral\n",
       "4  The Swedish buyout firm has sold its remaining...   neutral"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading the Dataset\n",
    "import pandas as pd\n",
    "df = pd.read_csv('Finance_data.csv')\n",
    "\n",
    "# Display the dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "caa4efb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5842x11143 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 70957 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pre-Prcoessing and Bag of Word Vectorization using Count Vectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
    "cv    = CountVectorizer(stop_words = 'english',ngram_range = (1, 1),tokenizer = token.tokenize)\n",
    "text_counts = cv.fit_transform(df['Sentence'])\n",
    "\n",
    "text_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d336e241",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data into trainig and testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(text_counts, df['Sentiment'], test_size=0.25, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3d75c42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5842, 11143), (4381, 11143), (1461, 11143), (4381,), (1461,))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_counts.shape, X_train.shape, X_test.shape, Y_train.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f008ddee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracuy Score:  0.6851471594798083\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "MNB = MultinomialNB()\n",
    "MNB.fit(X_train, Y_train)\n",
    "\n",
    "# Caluclating the accuracy score of the model\n",
    "from sklearn import metrics\n",
    "predicted = MNB.predict(X_test)\n",
    "accuracy_score = metrics.accuracy_score(predicted, Y_test)\n",
    "print(\"Accuracuy Score: \",accuracy_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c72ed0",
   "metadata": {},
   "source": [
    "The trained classifier can be used to predict the sentiment of any given text input."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c163f4",
   "metadata": {},
   "source": [
    "## References:\n",
    "* <p>https://www.analyticsvidhya.com/blog/2022/07/sentiment-analysis-using-python/</p>\n",
    "* <p>https://colab.research.google.com/drive/1_Y7LhR6t0Czsk3UOS3BC7quKDFnULlZG?usp=sharing#scrollTo=Mq87u2brC9L0</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
